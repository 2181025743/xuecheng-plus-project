# 分块文件清理机制实现方案

## 一、问题背景

### 1.1 断点续传流程回顾

**前端分块上传流程**：

```
用户选择文件（100MB）
↓
分块（5MB × 20块）
↓
逐块上传：
  第1块 → checkchunk → 不存在 → uploadchunk → 成功
  第2块 → checkchunk → 不存在 → uploadchunk → 成功
  ...
  第10块 → checkchunk → 不存在 → uploadchunk → ❌ 网络中断

用户重新上传（断点续传）：
  第1块 → checkchunk → 已存在 → 跳过 ✅
  第2块 → checkchunk → 已存在 → 跳过 ✅
  ...
  第10块 → checkchunk → 不存在 → uploadchunk → 成功
  ...
  第20块 → checkchunk → 不存在 → uploadchunk → 成功

所有分块上传完成
↓
mergeChunks → 合并 → MD5校验 → 上传OSS → 入库 → 清理分块 ✅
```

### 1.2 存在的问题

**场景 1：上传一半放弃**

- 用户上传了 50 块，然后关闭页面
- 这 50 块分块文件保存在服务器临时目录
- ❌ **永远不会被清理，成为垃圾文件**

**场景 2：上传失败**

- 用户上传完所有分块，但合并时失败（MD5 校验失败、OSS 上传失败等）
- 所有分块文件仍然保存在临时目录
- ❌ **可能不会被清理**

**场景 3：服务器重启**

- 上传过程中服务器重启
- 分块文件保存在临时目录（如 `/tmp/xc-chunks/`）
- 在 Linux 上，`/tmp` 目录重启后可能被清空（取决于系统配置）
- 在 Windows 上，临时目录不会自动清空
- ❌ **Windows 环境下会积累垃圾文件**

### 1.3 影响

- 磁盘空间浪费
- 临时目录文件过多，影响性能
- 无法追踪哪些是正常文件，哪些是垃圾文件

---

## 二、解决方案设计

### 2.1 方案选择

#### 方案 1：基于数据库状态的清理（视频中的方案）

**思路**：

1. 在 `media_files` 表中增加 `upload_status` 字段
2. 上传开始时插入记录，状态为"上传中"
3. 上传成功后更新状态为"已完成"
4. 定时任务扫描"上传中"且超过 24 小时的记录
5. 删除对应的分块文件和数据库记录

**优点**：

- 可追踪所有上传任务
- 精准清理
- 有审计记录

**缺点**：

- 需要修改表结构
- 上传开始就要写数据库（即使最终可能不上传）

#### 方案 2：基于文件时间戳的清理（推荐）

**思路**：

1. 不修改数据库结构
2. 定时任务直接扫描临时目录
3. 检查分块目录的最后修改时间
4. 如果超过 24 小时，直接删除整个分块目录

**优点**：

- 实现简单
- 不需要修改数据库
- 适用于所有未完成的上传

**缺点**：

- 无法追踪具体是哪个文件
- 无审计记录

#### 方案 3：混合方案（最佳实践）

**思路**：

1. 利用现有的 `status` 字段（1-正常，0-删除）
2. 新增 `upload_status` 字段（uploading/completed/failed）
3. 合并时才插入数据库记录，状态为"uploading"
4. 合并成功更新为"completed"
5. 合并失败更新为"failed"
6. 定时任务清理：
   - 数据库中"uploading"超过 24 小时的记录
   - 文件系统中超过 24 小时的分块目录

**优点**：

- 兼顾可追踪性和简洁性
- 双重保险（数据库+文件系统）
- 有完整的审计记录

### 2.2 推荐方案实施

我建议使用**方案 2（基于文件时间戳）**，因为：

1. 实现最简单
2. 不需要修改现有流程
3. 对于学习项目来说足够了

---

## 三、方案 2 实现：基于文件时间戳的清理

### 3.1 创建定时清理任务

**文件位置**：`xuecheng-plus-media/xuecheng-plus-media-service/src/main/java/com/xuecheng/media/task/ChunkCleanupTask.java`

```java
package com.xuecheng.media.task;

import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

import java.io.IOException;
import java.nio.file.DirectoryStream;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.nio.file.attribute.BasicFileAttributes;
import java.time.Instant;
import java.time.temporal.ChronoUnit;

/**
 * 分块文件清理定时任务
 *
 * 🎯 功能说明：
 * 定期清理超过指定时间的临时分块文件，防止磁盘空间浪费
 *
 * 📊 清理策略：
 * 1. 每天凌晨2点执行一次
 * 2. 扫描临时分块目录（/tmp/xc-chunks/）
 * 3. 检查每个分块目录的最后修改时间
 * 4. 删除超过24小时的分块目录
 *
 * 🔍 判断逻辑：
 * - 正常情况下，文件上传在几分钟到几小时内完成
 * - 超过24小时的分块目录，必定是中断/失败的上传
 * - 安全删除，不会影响正在进行的上传
 *
 * ⚠️ 注意事项：
 * - 时间阈值可配置（默认24小时）
 * - 删除前会记录详细日志
 * - 删除失败不影响任务继续执行
 *
 * @author AI Assistant
 * @version 1.0
 * @date 2025-10-07
 */
@Slf4j
@Component
public class ChunkCleanupTask {

    /**
     * 分块文件根目录
     */
    private static final String CHUNK_ROOT = System.getProperty("java.io.tmpdir") + "/xc-chunks";

    /**
     * 清理阈值（小时）
     */
    private static final int CLEANUP_THRESHOLD_HOURS = 24;

    /**
     * 定时清理任务
     *
     * cron表达式：0 0 2 * * ?
     * - 秒：0
     * - 分：0
     * - 时：2（凌晨2点）
     * - 日：*（每天）
     * - 月：*（每月）
     * - 星期：?（不指定）
     *
     * 执行时间：每天凌晨2点执行一次
     */
    @Scheduled(cron = "0 0 2 * * ?")
    public void cleanupOldChunks() {
        log.info("========== 开始执行分块文件清理任务 ==========");

        Path rootPath = Paths.get(CHUNK_ROOT);

        // 检查根目录是否存在
        if (!Files.exists(rootPath)) {
            log.info("分块根目录不存在，无需清理：{}", CHUNK_ROOT);
            return;
        }

        int totalDirs = 0;      // 总目录数
        int deletedDirs = 0;    // 删除的目录数
        long freedSpace = 0;    // 释放的空间（字节）

        try (DirectoryStream<Path> stream = Files.newDirectoryStream(rootPath)) {
            for (Path chunkDir : stream) {
                // 只处理目录
                if (!Files.isDirectory(chunkDir)) {
                    continue;
                }

                totalDirs++;

                try {
                    // 获取目录的最后修改时间
                    BasicFileAttributes attrs = Files.readAttributes(chunkDir, BasicFileAttributes.class);
                    Instant lastModified = attrs.lastModifiedTime().toInstant();
                    Instant threshold = Instant.now().minus(CLEANUP_THRESHOLD_HOURS, ChronoUnit.HOURS);

                    // 判断是否超过阈值
                    if (lastModified.isBefore(threshold)) {
                        // 计算目录大小
                        long dirSize = calculateDirSize(chunkDir);

                        // 删除目录及其所有内容
                        deleteDirectory(chunkDir);

                        deletedDirs++;
                        freedSpace += dirSize;

                        log.info("✅ 清理过期分块目录：{}，大小：{}MB，最后修改时间：{}",
                                chunkDir.getFileName(),
                                dirSize / 1024 / 1024,
                                lastModified);
                    } else {
                        log.debug("分块目录未过期，跳过：{}，最后修改时间：{}",
                                chunkDir.getFileName(), lastModified);
                    }

                } catch (Exception e) {
                    log.error("处理分块目录失败：{}，错误：{}", chunkDir, e.getMessage(), e);
                    // 继续处理下一个目录
                }
            }
        } catch (IOException e) {
            log.error("扫描分块根目录失败：{}", e.getMessage(), e);
        }

        log.info("========== 分块文件清理任务完成 ==========");
        log.info("扫描目录数：{}，清理目录数：{}，释放空间：{}MB",
                totalDirs, deletedDirs, freedSpace / 1024 / 1024);
    }

    /**
     * 计算目录大小
     */
    private long calculateDirSize(Path dir) {
        long size = 0;
        try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir)) {
            for (Path file : stream) {
                if (Files.isRegularFile(file)) {
                    size += Files.size(file);
                }
            }
        } catch (IOException e) {
            log.warn("计算目录大小失败：{}", dir, e);
        }
        return size;
    }

    /**
     * 递归删除目录
     */
    private void deleteDirectory(Path dir) throws IOException {
        // 先删除目录中的所有文件
        try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir)) {
            for (Path file : stream) {
                if (Files.isDirectory(file)) {
                    // 递归删除子目录
                    deleteDirectory(file);
                } else {
                    // 删除文件
                    Files.deleteIfExists(file);
                }
            }
        }
        // 最后删除空目录
        Files.deleteIfExists(dir);
    }

    /**
     * 手动触发清理（用于测试）
     *
     * 可以通过JMX或HTTP接口调用此方法进行手动清理
     */
    public void manualCleanup() {
        log.info("手动触发分块文件清理任务");
        cleanupOldChunks();
    }
}
```

### 3.2 启用定时任务

**文件位置**：`xuecheng-plus-media/xuecheng-plus-media-api/src/main/java/com/xuecheng/MediaApplication.java`

在启动类上添加 `@EnableScheduling` 注解：

```java
package com.xuecheng;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.scheduling.annotation.EnableScheduling;

@SpringBootApplication
@EnableScheduling  // 启用定时任务
public class MediaApplication {
    public static void main(String[] args) {
        SpringApplication.run(MediaApplication.class, args);
    }
}
```

### 3.3 配置清理参数（可选）

**文件位置**：`nacos-config-media-service-dev.yaml`（Nacos 配置）

```yaml
# 分块文件清理配置
chunk:
  cleanup:
    enabled: true # 是否启用清理任务
    cron: "0 0 2 * * ?" # 执行时间（每天凌晨2点）
    threshold-hours: 24 # 清理阈值（小时）
```

---

## 四、增强版清理方案（方案 3）

如果你想要更完善的方案，可以结合数据库状态：

### 4.1 数据库表增强

**添加 upload_status 字段**（可选）：

```sql
-- 为 media_files 表添加上传状态字段
ALTER TABLE media_files
ADD COLUMN upload_status VARCHAR(20) DEFAULT 'completed' COMMENT '上传状态：uploading-上传中，completed-已完成，failed-失败';

-- 添加索引，便于定时任务查询
CREATE INDEX idx_upload_status_time
ON media_files(upload_status, create_date);
```

### 4.2 修改合并流程

在 `MediaFileServiceImpl.java` 的 `mergechunks` 方法中：

```java
@Override
public RestResponse mergechunks(Long companyId, String fileMd5, int chunkTotal,
        UploadFileParamsDto uploadFileParamsDto) {

    // ===== 步骤1：创建"上传中"记录 =====
    MediaFiles uploadingRecord = new MediaFiles();
    uploadingRecord.setId(fileMd5);
    uploadingRecord.setCompanyId(companyId);
    uploadingRecord.setFilename(uploadFileParamsDto.getFilename());
    uploadingRecord.setUploadStatus("uploading");  // 标记为上传中
    uploadingRecord.setCreateDate(LocalDateTime.now());

    try {
        // 尝试插入"上传中"记录
        mediaFilesMapper.insert(uploadingRecord);
    } catch (Exception e) {
        // 如果记录已存在，更新状态为"uploading"
        uploadingRecord.setUploadStatus("uploading");
        mediaFilesMapper.updateById(uploadingRecord);
    }

    try {
        // ===== 步骤2-5：原有的合并逻辑 =====
        // ... 检查分块、合并、MD5校验、上传OSS、入库 ...

        // ===== 步骤6：更新状态为"已完成" =====
        mediaFiles.setUploadStatus("completed");
        mediaFilesMapper.updateById(mediaFiles);

        // ===== 步骤7：清理临时文件 =====
        // ... 清理分块 ...

        return RestResponse.success(true);

    } catch (Exception e) {
        // ===== 合并失败，更新状态为"失败" =====
        uploadingRecord.setUploadStatus("failed");
        uploadingRecord.setRemark("合并失败：" + e.getMessage());
        mediaFilesMapper.updateById(uploadingRecord);

        log.error("合并文件异常，MD5：{}，错误信息：{}", fileMd5, e.getMessage(), e);
        return RestResponse.validfail(false, "合并文件异常：" + e.getMessage());
    }
}
```

### 4.3 增强版清理任务

```java
@Scheduled(cron = "0 0 2 * * ?")
public void cleanupOldChunks() {
    log.info("========== 开始执行分块文件清理任务 ==========");

    // ===== 清理1：基于数据库状态的清理 =====
    cleanupByDatabaseStatus();

    // ===== 清理2：基于文件时间戳的清理（兜底） =====
    cleanupByFileTimestamp();

    log.info("========== 分块文件清理任务完成 ==========");
}

/**
 * 基于数据库状态的清理
 */
private void cleanupByDatabaseStatus() {
    // 查询"上传中"且超过24小时的记录
    LocalDateTime threshold = LocalDateTime.now().minusHours(24);
    LambdaQueryWrapper<MediaFiles> wrapper = new LambdaQueryWrapper<>();
    wrapper.eq(MediaFiles::getUploadStatus, "uploading")
           .lt(MediaFiles::getCreateDate, threshold);

    List<MediaFiles> oldUploads = mediaFilesMapper.selectList(wrapper);

    for (MediaFiles file : oldUploads) {
        try {
            // 删除分块文件
            Path chunkDir = getChunkRootPath(file.getId());
            if (Files.exists(chunkDir)) {
                deleteDirectory(chunkDir);
                log.info("✅ 清理数据库关联的分块：MD5={}，文件名：{}",
                        file.getId(), file.getFilename());
            }

            // 删除数据库记录
            mediaFilesMapper.deleteById(file.getId());

        } catch (Exception e) {
            log.error("清理失败：MD5={}", file.getId(), e);
        }
    }
}

/**
 * 基于文件时间戳的清理（兜底）
 */
private void cleanupByFileTimestamp() {
    // ... 方案2的实现 ...
}
```

---

## 五、当前项目的最佳实践

基于你的项目情况，我建议采用**简化版的方案 2**：

### 5.1 实施步骤

#### Step 1: 创建清理任务类

将上面的 `ChunkCleanupTask.java` 创建到：

```
xuecheng-plus-media/xuecheng-plus-media-service/src/main/java/com/xuecheng/media/task/
```

#### Step 2: 启用定时任务

在 `MediaApplication.java` 上添加 `@EnableScheduling`

#### Step 3: 配置清理参数（可选）

在 Nacos 配置中添加：

```yaml
chunk:
  cleanup:
    enabled: true
    cron: "0 0 2 * * ?" # 每天凌晨2点
    threshold-hours: 24
```

#### Step 4: 测试清理任务

```java
// 添加测试接口（仅开发环境）
@RestController
@RequestMapping("/test")
public class TestController {
    @Autowired
    private ChunkCleanupTask cleanupTask;

    @GetMapping("/cleanup-chunks")
    public String testCleanup() {
        cleanupTask.manualCleanup();
        return "清理任务已执行";
    }
}
```

---

## 六、其他优化建议

### 6.1 合并成功后立即清理

**当前实现**（已有）：

```java
// 合并成功后清理
for (int i = 0; i < chunkTotal; i++) {
    Files.deleteIfExists(chunkRoot.resolve(String.valueOf(i)));
}
Files.deleteIfExists(chunkRoot);
```

✅ 这个已经做得很好了

### 6.2 合并失败后也清理

**优化建议**：

```java
} catch (Exception e) {
    // 记录异常
    log.error("合并文件异常，MD5：{}", fileMd5, e);

    // 清理已合并的临时文件
    try {
        if (merged != null && Files.exists(merged)) {
            Files.deleteIfExists(merged);
        }
    } catch (Exception cleanEx) {
        log.warn("清理临时文件失败", cleanEx);
    }

    // 注意：分块文件不删除，便于用户重试

    return RestResponse.validfail(false, "合并文件异常：" + e.getMessage());
}
```

### 6.3 增加分块目录大小限制

防止恶意上传占满磁盘：

```java
@Override
public RestResponse uploadChunk(String fileMd5, int chunk, String localChunkFilePath) {
    try {
        Path root = getChunkRootPath(fileMd5);

        // 检查当前分块目录的总大小
        long currentSize = calculateDirSize(root);
        long maxSize = 5L * 1024 * 1024 * 1024;  // 单个文件最大5GB

        if (currentSize > maxSize) {
            log.error("分块目录超过最大限制：{}MB", currentSize / 1024 / 1024);
            return RestResponse.validfail(false, "文件过大，超过5GB限制");
        }

        // ... 原有的上传逻辑 ...
    }
}
```

---

## 七、监控与告警

### 7.1 添加监控指标

```java
@Component
public class ChunkMetrics {

    private final AtomicLong totalChunkDirs = new AtomicLong(0);
    private final AtomicLong totalChunkSize = new AtomicLong(0);

    /**
     * 定时统计分块文件情况
     */
    @Scheduled(fixedDelay = 60000)  // 每分钟统计一次
    public void collectMetrics() {
        Path rootPath = Paths.get(CHUNK_ROOT);
        if (!Files.exists(rootPath)) {
            return;
        }

        long dirCount = 0;
        long totalSize = 0;

        try (DirectoryStream<Path> stream = Files.newDirectoryStream(rootPath)) {
            for (Path dir : stream) {
                if (Files.isDirectory(dir)) {
                    dirCount++;
                    totalSize += calculateDirSize(dir);
                }
            }
        } catch (IOException e) {
            log.error("统计分块文件失败", e);
        }

        totalChunkDirs.set(dirCount);
        totalChunkSize.set(totalSize);

        // 告警：如果分块目录超过100个
        if (dirCount > 100) {
            log.warn("⚠️ 分块目录数量过多：{}个，建议检查是否有大量未完成的上传", dirCount);
        }

        // 告警：如果总大小超过10GB
        if (totalSize > 10L * 1024 * 1024 * 1024) {
            log.warn("⚠️ 分块文件占用空间过大：{}GB，建议执行清理任务",
                    totalSize / 1024 / 1024 / 1024);
        }
    }

    // 提供接口查询当前状态
    public long getChunkDirCount() {
        return totalChunkDirs.get();
    }

    public long getChunkTotalSize() {
        return totalChunkSize.get();
    }
}
```

### 7.2 暴露管理接口

```java
@RestController
@RequestMapping("/admin/chunk")
public class ChunkManagementController {

    @Autowired
    private ChunkCleanupTask cleanupTask;

    @Autowired
    private ChunkMetrics chunkMetrics;

    /**
     * 查询当前分块文件状态
     */
    @GetMapping("/status")
    public Map<String, Object> getStatus() {
        Map<String, Object> result = new HashMap<>();
        result.put("dirCount", chunkMetrics.getChunkDirCount());
        result.put("totalSize", chunkMetrics.getChunkTotalSize());
        result.put("totalSizeMB", chunkMetrics.getChunkTotalSize() / 1024 / 1024);
        return result;
    }

    /**
     * 手动触发清理
     */
    @PostMapping("/cleanup")
    public String manualCleanup() {
        cleanupTask.manualCleanup();
        return "清理任务已执行";
    }
}
```

---

## 八、清理任务的最佳实践

### 8.1 清理时机选择

| 时机          | Cron 表达式     | 说明                   | 推荐        |
| ------------- | --------------- | ---------------------- | ----------- |
| 每天凌晨 2 点 | `0 0 2 * * ?`   | 用户使用最少的时段     | ✅ 推荐     |
| 每 6 小时     | `0 0 */6 * * ?` | 更频繁，但可能影响性能 | ⚠️ 高频场景 |
| 每周日凌晨    | `0 0 2 ? * SUN` | 频率较低               | ❌ 不推荐   |

### 8.2 清理阈值选择

| 阈值    | 适用场景   | 风险                         |
| ------- | ---------- | ---------------------------- |
| 1 小时  | 测试环境   | ⚠️ 可能误删正在上传的大文件  |
| 6 小时  | 小文件场景 | ⚠️ 大文件上传可能超过 6 小时 |
| 24 小时 | 一般场景   | ✅ 平衡安全性和及时性        |
| 72 小时 | 谨慎清理   | ❌ 垃圾文件积累时间长        |

**推荐**：24 小时（默认）

### 8.3 清理策略

**策略 1：保守清理**

- 只删除确定不会再用的文件
- 清理阈值较长（48-72 小时）
- 适合存储空间充足的场景

**策略 2：激进清理**

- 及时清理可能的垃圾文件
- 清理阈值较短（6-12 小时）
- 适合存储空间紧张的场景

**策略 3：智能清理（推荐）**

- 结合数据库状态和文件时间戳
- 对"已完成"的文件，立即清理分块
- 对"上传中"的文件，24 小时后清理
- 对无记录的文件，24 小时后清理

---

## 九、实施建议

### 对于你的项目

考虑到你的项目是学习项目，我建议：

1. **现阶段（推荐）**：

   - 实施简单的基于时间戳的清理（方案 2）
   - 每天凌晨 2 点执行
   - 24 小时阈值
   - 不修改数据库表结构

2. **进阶阶段**（可选）：

   - 添加 `upload_status` 字段
   - 实施混合清理方案（方案 3）
   - 增加监控和告警

3. **生产环境**（未来）：
   - 使用分布式定时任务（如 XXL-JOB）
   - 增加清理任务的幂等性保证
   - 集成监控系统（Prometheus + Grafana）
   - 设置告警规则

---

## 十、总结

### 视频核心要点

1. **断点续传原理**：

   - 前端分块上传
   - 每块上传前先检查是否已存在
   - 已存在的块不重复上传
   - 所有块上传完成后合并

2. **分块文件清理**：
   - 问题：上传失败的分块会占用空间
   - 解决：定时任务扫描并清理过期文件
   - 判断：基于时间戳或数据库状态

### 你的项目现状

✅ **已实现**：

- 完整的分块上传流程
- MD5 校验机制
- 合并成功后的立即清理

❌ **待优化**：

- 定时清理任务（防止垃圾文件积累）

### 推荐实施步骤

1. **立即实施**：创建 `ChunkCleanupTask` 定时任务
2. **下次优化**：添加 `upload_status` 字段
3. **生产上线前**：添加监控和告警

---

## 十一、相关文件清单

### 需要创建的文件

- `xuecheng-plus-media-service/src/main/java/com/xuecheng/media/task/ChunkCleanupTask.java`

### 需要修改的文件

- `xuecheng-plus-media-api/src/main/java/com/xuecheng/MediaApplication.java` - 添加 `@EnableScheduling`

### 可选优化

- `media_files` 表 - 添加 `upload_status` 字段
- `MediaFileServiceImpl.java` - 增强合并流程的状态管理

---

**要我现在为你创建这个清理任务吗？还是先把视频上传的主流程完全跑通再说？**
